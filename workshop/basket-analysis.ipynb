{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"images/basket-equation.png\" alt=\"Support, Confidence, and Lift metrics\" width=\"882\" height=\"446\">\n",
    "</div>"
   ],
   "id": "b7542c410573568b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import collect_set, expr\n",
    "from pyspark.ml.fpm import FPGrowth\n",
    "from wordcloud import WordCloud"
   ],
   "id": "ee4395e1a8f3830f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "spark = (SparkSession.builder\n",
    "         .appName(\"basket-analysis\")\n",
    "         .enableHiveSupport()\n",
    "         .config(\"spark.driver.memory\", \"3g\")\n",
    "         .config(\"spark.executor.memory\", \"3g\")\n",
    "         .getOrCreate())"
   ],
   "id": "9d307028bda2bedb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "INSTACART_DATA = \"../data/instacart\"",
   "id": "2ad527bdcd09f138",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "aisles = spark.read.csv(f\"{INSTACART_DATA}/aisles.csv\", header=True, inferSchema=True)\n",
    "departments = spark.read.csv(f\"{INSTACART_DATA}/departments.csv\", header=True, inferSchema=True)\n",
    "order_products_prior = spark.read.csv(f\"{INSTACART_DATA}/order_products__prior.csv\", header=True, inferSchema=True)\n",
    "order_products_train = spark.read.csv(f\"{INSTACART_DATA}/order_products__train.csv\", header=True, inferSchema=True)\n",
    "orders = spark.read.csv(f\"{INSTACART_DATA}/orders.csv\", header=True, inferSchema=True)\n",
    "products = spark.read.csv(f\"{INSTACART_DATA}/products.csv\", header=True, inferSchema=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "aisles.createOrReplaceTempView(\"aisles\")\n",
    "departments.createOrReplaceTempView(\"departments\")\n",
    "order_products_prior.createOrReplaceTempView(\"order_products_prior\")\n",
    "order_products_train.createOrReplaceTempView(\"order_products_train\")\n",
    "orders.createOrReplaceTempView(\"orders\")\n",
    "products.createOrReplaceTempView(\"products\")"
   ],
   "id": "1ec3c91e4ebe9368",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "orders.show(n=5)",
   "id": "ed9788766619b47f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "products.show(n=5)",
   "id": "4523bf707c157f9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "aisles.show(n=5)",
   "id": "362ae9796e755256",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "departments.show(n=5)",
   "id": "4cadc4e977c8f1ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "order_products_train.show(n=5)",
   "id": "4baea97db4c323e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "order_products_prior.show(n=5)",
   "id": "49a3be1e79d39cf5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query = \"\"\"\n",
    "select count(order_id) as total_orders, order_hour_of_day as hour \n",
    "from orders \n",
    "group by order_hour_of_day \n",
    "order by order_hour_of_day\n",
    "\"\"\"\n",
    "orders_by_hour = spark.sql(query)\n",
    "orders_by_hour.show(10)"
   ],
   "id": "ff6c904285252110",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "orders_by_hour_plot = orders_by_hour.toPandas()\n",
    "\n",
    "# Plot using seaborn and matplotlib\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x='hour', y='total_orders', data=orders_by_hour_plot, marker='o', markersize=6)\n",
    "\n",
    "# Adding circles around the points\n",
    "for i in range(orders_by_hour_plot.shape[0]):\n",
    "    plt.scatter(orders_by_hour_plot['hour'][i], orders_by_hour_plot['total_orders'][i], s=200, facecolors='none', edgecolors='r')\n",
    "\n",
    "plt.title('Total Orders by Hour of the Day')\n",
    "plt.xlabel('Hour of the Day')\n",
    "plt.ylabel('Total Orders')\n",
    "plt.xticks(range(24))  # Assuming the hours are in the range 0-23\n",
    "plt.show()"
   ],
   "id": "9f382cf2abbeb4f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query = \"\"\"\n",
    "select days_since_prior_order, count(order_id) as total_orders\n",
    "from orders \n",
    "group by days_since_prior_order \n",
    "order by days_since_prior_order\n",
    "\"\"\"\n",
    "days_since_prior_order = spark.sql(query)\n",
    "days_since_prior_order.show(10)"
   ],
   "id": "d2635caf4a1cb8ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "days_since_prior_order_plot = days_since_prior_order.toPandas()\n",
    "\n",
    "# Plot using seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='days_since_prior_order', y='total_orders', data=days_since_prior_order_plot, \n",
    "            palette='viridis', hue='days_since_prior_order', dodge=False, legend=False)\n",
    "\n",
    "plt.title('Total Orders by Days Since Prior Order')\n",
    "plt.xlabel('Days Since Prior Order')\n",
    "plt.ylabel('Total Orders')\n",
    "plt.show()"
   ],
   "id": "d9dd114465d1e51",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query = \"\"\"\n",
    "select count(order_id) as total_orders, \n",
    "  (case \n",
    "     when order_dow = '0' then 'Sunday'\n",
    "     when order_dow = '1' then 'Monday'\n",
    "     when order_dow = '2' then 'Tuesday'\n",
    "     when order_dow = '3' then 'Wednesday'\n",
    "     when order_dow = '4' then 'Thursday'\n",
    "     when order_dow = '5' then 'Friday'\n",
    "     when order_dow = '6' then 'Saturday'              \n",
    "   end) as day_of_week \n",
    "  from orders  \n",
    " group by order_dow \n",
    " order by total_orders desc\n",
    "\"\"\"\n",
    "order_by_weekday = spark.sql(query)\n",
    "order_by_weekday.show()"
   ],
   "id": "d36c41a16c509826",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "order_by_weekday_plot = order_by_weekday.toPandas()\n",
    "\n",
    "# Plot using seaborn with 'Blues' palette\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='day_of_week', y='total_orders', hue='day_of_week', data=order_by_weekday_plot,\n",
    "            palette='viridis', dodge=False, legend=False)\n",
    "\n",
    "plt.title('Total Orders by Day of the Week')\n",
    "plt.xlabel('Day of the Week')\n",
    "plt.ylabel('Total Orders')\n",
    "plt.show()"
   ],
   "id": "7bec1c4f06ee9a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS order_items_temp\")\n",
    "\n",
    "query = \"\"\"\n",
    "create table order_items_temp as\n",
    "(select op.*, p.product_name, p.aisle_id, p.department_id, d.department from\n",
    " (select * from order_products_train \n",
    " union\n",
    " select * from order_products_prior) as op\n",
    " inner join products as p\n",
    " on op.product_id = p.product_id\n",
    " inner join departments as d\n",
    " on p.department_id = d.department_id)\n",
    "\"\"\"\n",
    "spark.sql(query)"
   ],
   "id": "11a43d1acc1748cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query = \"\"\"\n",
    "select order_id, count(product_id) as total_items\n",
    "from order_items_temp \n",
    "group by order_id\n",
    "\"\"\"\n",
    "items_by_order = spark.sql(query)\n",
    "items_by_order.show(10)"
   ],
   "id": "5f6e95fdf1c813ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query = \"\"\"\n",
    "select total_items, count(order_id) as num_orders\n",
    "from (\n",
    "    select order_id, count(product_id) as total_items\n",
    "    from order_items_temp \n",
    "    group by order_id\n",
    ") as items_by_order\n",
    "group by total_items\n",
    "order by total_items\n",
    "\"\"\"\n",
    "items_by_order_aggregated = spark.sql(query)\n",
    "items_by_order_aggregated.show(10)"
   ],
   "id": "8cd0f550ff696774",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "items_by_order_plot = items_by_order_aggregated.toPandas()\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "bar_plot = sns.barplot(x='total_items', y='num_orders', data=items_by_order_plot, \n",
    "            hue='total_items', palette='viridis', dodge=False, legend=False)\n",
    "\n",
    "bar_plot.xaxis.set_major_locator(ticker.MultipleLocator(4))\n",
    "bar_plot.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f'{int(x/1000)}k'))\n",
    "\n",
    "plt.title('Number of Orders by Total Items')\n",
    "plt.xlabel('Total Items')\n",
    "plt.ylabel('Number of Orders')\n",
    "plt.show()"
   ],
   "id": "1330d777a7344659",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query = \"\"\"\n",
    "select department, count(*) as orders_count from order_items_temp\n",
    "group by department\n",
    "order by orders_count desc\n",
    "limit 10\n",
    "\"\"\"\n",
    "orders_by_department = spark.sql(query)\n",
    "orders_by_department.show()"
   ],
   "id": "dcd5a53f9168316a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "orders_by_department_plot = orders_by_department.toPandas()\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.pie(orders_by_department_plot['orders_count'], labels=orders_by_department_plot['department'],\n",
    "        autopct='%1.1f%%', startangle=140)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(orders_by_department_plot['department'], title=\"Departments\", bbox_to_anchor=(1.05, 1), loc='best')\n",
    "\n",
    "plt.title('Top 10 Departments by Order Count')\n",
    "plt.show()"
   ],
   "id": "83c4618aa1959766",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query = \"\"\"\n",
    "select product_name, count(*) as orders_count from order_items_temp\n",
    "group by product_name\n",
    "order by orders_count desc\n",
    "limit 200\n",
    "\"\"\"\n",
    "product_by_order = spark.sql(query)\n",
    "product_by_order.show(10)"
   ],
   "id": "af23031ab1a7c873",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query = \"\"\"\n",
    "SELECT product_name\n",
    "FROM (\n",
    "  SELECT product_name, count(*) AS orders_count\n",
    "  FROM order_items_temp\n",
    "  GROUP BY product_name\n",
    "  ORDER BY orders_count DESC\n",
    "  LIMIT 200\n",
    ")\n",
    "\"\"\"\n",
    "words_df = spark.sql(query)\n",
    "words = words_df.rdd.flatMap(lambda x: x).collect()\n",
    "words_str = ' '.join(words)\n",
    "word_cloud = WordCloud(background_color=\"white\").generate(words_str)"
   ],
   "id": "edb270c7a137b1ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "plt.imshow(word_cloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "display()"
   ],
   "id": "795d78a85bbd8a37",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query = \"\"\"\n",
    "SELECT products.product_name, order_products.order_id \n",
    "FROM products \n",
    "INNER JOIN order_products_train AS order_products  \n",
    "WHERE order_products.product_id = products.product_id\n",
    "\"\"\"\n",
    "\n",
    "raw_data = spark.sql(query)\n",
    "raw_data.show(5, truncate=False)"
   ],
   "id": "b111f1355d3d7e05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "baskets = raw_data.groupBy('order_id').agg(collect_set('product_name').alias('items'))\n",
    "baskets.createOrReplaceTempView('baskets')\n",
    "baskets.show(5, truncate=False)"
   ],
   "id": "61e60f8044b7506",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query = \"\"\"\n",
    "SELECT items from baskets\n",
    "\"\"\" \n",
    "\n",
    "baskets_items = spark.sql(query).withColumn('items', expr('TRANSFORM(items, x -> CAST(x AS STRING))'))\n",
    "baskets_items.show(5, truncate=False)"
   ],
   "id": "847a34afa5a51e27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fpgrowth = FPGrowth().setItemsCol(\"items\").setMinSupport(0.001).setMinConfidence(0)\n",
    "model = fpgrowth.fit(baskets_items)"
   ],
   "id": "b662962dae42b075",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "most_popular_item_in_basket = model.freqItemsets\n",
    "most_popular_item_in_basket.createOrReplaceTempView(\"most_popular_item_in_basket\")"
   ],
   "id": "5867a5f1ccf08a55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if_then = model.associationRules\n",
    "if_then.createOrReplaceTempView(\"if_then\")"
   ],
   "id": "2c440ca0ca019f2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query = \"\"\"\n",
    "SELECT items, freq\n",
    "FROM most_popular_item_in_basket \n",
    "WHERE SIZE(items) > 2 \n",
    "ORDER BY freq desc\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "items_freq = spark.sql(query)\n",
    "items_freq.show(5, truncate=False)"
   ],
   "id": "965bc06a8a33499b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query = \"\"\"\n",
    "SELECT antecedent as `antecedent (if)`, consequent as `consequent (then)`, confidence \n",
    "FROM if_then \n",
    "ORDER BY confidence DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "confidence = spark.sql(query)\n",
    "confidence.show(5, truncate=False)"
   ],
   "id": "24bf4a5174c01192",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query = \"\"\"\n",
    "SELECT * FROM if_then \n",
    "WHERE lift > 1\n",
    "ORDER BY lift DESC\n",
    "\"\"\"\n",
    "\n",
    "lift = spark.sql(query)\n",
    "lift.show(5, truncate=False)"
   ],
   "id": "55d630ce175bc930",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
